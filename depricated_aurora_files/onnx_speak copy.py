# file: onnx_speak.py
import onnxruntime as ort
import numpy as np
import sounddevice as sd
import scipy.io.wavfile as wavfile
import os
from misaki import en
import asyncio
import websockets

# Initialize once
g2p = en.G2P(trf=False, british=False, fallback=None)
# üìÇ Model path
MODEL_PATH = "E:/AURORA/kokoro/model_q8f16.onnx"
OUTPUT_WAV = "E:/AURORA/piper/output.wav"

# üéöÔ∏è Voice control params
TEMPERATURE = 0.7  # 0.0 = deterministic, 1.0 = creative
NOISE_SCALE = 0.5  # 0.0 = perfect, 1.0 = noisy/playful
VOCAB = {
    ";": 1,
    ":": 2,
    ",": 3,
    ".": 4,
    "!": 5,
    "?": 6,
    "‚Äî": 9,
    "‚Ä¶": 10,
    "\"": 11,
    "(": 12,
    ")": 13,
    "‚Äú": 14,
    "‚Äù": 15,
    " ": 16,
    "\u0303": 17,
    " £": 18,
    " •": 19,
    " ¶": 20,
    " ®": 21,
    "·µù": 22,
    "\uAB67": 23,
    "A": 24,
    "I": 25,
    "O": 31,
    "Q": 33,
    "S": 35,
    "T": 36,
    "W": 39,
    "Y": 41,
    "·µä": 42,
    "a": 43,
    "b": 44,
    "c": 45,
    "d": 46,
    "e": 47,
    "f": 48,
    "h": 50,
    "i": 51,
    "j": 52,
    "k": 53,
    "l": 54,
    "m": 55,
    "n": 56,
    "o": 57,
    "p": 58,
    "q": 59,
    "r": 60,
    "s": 61,
    "t": 62,
    "u": 63,
    "v": 64,
    "w": 65,
    "x": 66,
    "y": 67,
    "z": 68,
    "…ë": 69,
    "…ê": 70,
    "…í": 71,
    "√¶": 72,
    "Œ≤": 75,
    "…î": 76,
    "…ï": 77,
    "√ß": 78,
    "…ñ": 80,
    "√∞": 81,
    " §": 82,
    "…ô": 83,
    "…ö": 85,
    "…õ": 86,
    "…ú": 87,
    "…ü": 90,
    "…°": 92,
    "…•": 99,
    "…®": 101,
    "…™": 102,
    " ù": 103,
    "…Ø": 110,
    "…∞": 111,
    "≈ã": 112,
    "…≥": 113,
    "…≤": 114,
    "…¥": 115,
    "√∏": 116,
    "…∏": 118,
    "Œ∏": 119,
    "≈ì": 120,
    "…π": 123,
    "…æ": 125,
    "…ª": 126,
    " Å": 128,
    "…Ω": 129,
    " Ç": 130,
    " É": 131,
    " à": 132,
    " ß": 133,
    " ä": 135,
    " ã": 136,
    " å": 138,
    "…£": 139,
    "…§": 140,
    "œá": 142,
    " é": 143,
    " í": 147,
    " î": 148,
    "Àà": 156,
    "Àå": 157,
    "Àê": 158,
    " ∞": 162,
    " ≤": 164,
    "‚Üì": 169,
    "‚Üí": 171,
    "‚Üó": 172,
    "‚Üò": 173,
    "·µª": 177
  }

# üß† Load the ONNX model (only once)
session = ort.InferenceSession(MODEL_PATH)

def text_to_tokens(text):
    tokens = []
    for c in text:
        tokens.append(VOCAB.get(c, 16))
    return tokens

async def synthesize(text: str):
    phonemes, _ = g2p(text)
    tokens = text_to_tokens(phonemes)
    if len(tokens) > 510:
        tokens = tokens[:510]

    voices = np.fromfile('E:/AURORA/kokoro/af_bella.bin', dtype=np.float32).reshape(-1, 1, 256)
    ref_s = voices[len(tokens)]  # Style vector based on text length

    tokens = [[0, *tokens, 0]]
    # before running session
    inputs = {
        "input_ids": tokens,
        "style": ref_s,   # Use style index 0
        "speed": np.ones(1, dtype=np.float32)
    }


    output = session.run(None, inputs)[0]


    audio = output[0].squeeze()  # (samples,)
    audio = np.clip(audio, -1, 1)  # ensure safe range

    # Save to WAV
    wavfile.write(OUTPUT_WAV, 24000, (audio * 32767).astype(np.int16))
    print(f"[‚úÖ Saved]: {OUTPUT_WAV}")
    
    #send phonemes to Unity model
    #asyncio.create_task(send_phonemes(phonemes))
    #play audio (now sending to Unity to handle)
    #play_audio(OUTPUT_WAV)
    
async def notify_unity_audio_ready():
    uri = "ws://localhost:12347"  # New WebSocket for Unity notifications
    try:
        async with websockets.connect(uri) as websocket:
            await websocket.send("new_audio_ready")
    except Exception as e:
        print(f"‚ö†Ô∏è WebSocket error: {e}")

def play_audio(path: str):
    """Play a WAV audio file."""
    if not os.path.exists(path):
        print(f"‚ö†Ô∏è Audio file not found: {path}")
        return
    samplerate, data = wavfile.read(path)
    sd.play(data, samplerate)
    sd.wait()


def speak(text: str):
    asyncio.run(synthesize(text))
    asyncio.run(notify_unity_audio_ready())

# üõë No executable code at bottom
